{"prompt": "Libipuz is a C library that loads puzzle files for Crosswords, and it's primarily used for parsing files from disk. Rewriting this in Rust would improve memory safety, error handling, and maintainability, especially for file I/O operations and multi-threaded parsing.", "completion": "175 hours, Medium"}
{"prompt": "FlatSync is a GSoC 2023 project aimed at synchronizing Flatpak installations across multiple machines. The goal for GSoC 2024 is to implement machine-specific synchronization, improve error handling, and enhance the user interface with an initial setup wizard and the ability to exclude specific Flatpaks based on system configuration.", "completion": "175 hours, Medium"}
{"prompt": "Valadoc is the API documentation generator for the Vala programming language. To support modern GObject-Introspection attributes, such as marking methods as getters or setters, changes need to be made both to the Vala compiler and the Valadoc documentation generator. These updates will enhance language binding and documentation support.", "completion": "90 hours, Medium"}
{"prompt": "Bustle's diagram tool, used for visualizing service interactions, suffers from several usability issues: unreadable arrows for concurrent calls, poor time representation, and inadequate RTL (Right-to-Left) layout support. A complete overhaul is needed to fix these issues while maintaining compatibility with the old diagram view.", "completion": "175 hours, Medium"}
{"prompt": "The GNOME Terminal project faces issues with high CPU usage and memory leaks. Refactoring the codebase to optimize rendering and resource usage, including using more efficient event handling and memory management techniques, will be key to improving performance.", "completion": "350 hours, Hard"}
{"prompt": "GNOME Files is the default file manager for GNOME. Refactoring the codebase to address high CPU usage and memory leaks involves optimizing the file system access layer and improving the performance of common file operations like search, copy, and move. The project also requires testing on different architectures to ensure compatibility.", "completion": "350 hours, Hard"}
{"prompt": "Develop a web IDE for Tracker SPARQL, focusing on building an intuitive user interface in HTML and JavaScript. Additionally, optimize the C and GObject code behind the IDE to handle complex queries efficiently, ensuring the system can scale with large datasets.", "completion": "350 hours, Hard"}
{"prompt": "Workbench is a multi-language code sandbox that needs several architectural changes. These include removing the inline previewer for JavaScript, adding an out-of-process previewer for better performance, and refactoring the internal previewer architecture to create a unified, introspectable library.", "completion": "350 hours, Hard"}
{"prompt": "Create a Rust-based proof of concept to integrate Server-Side Rendering (SSR) with TypeScript in Actix. The task involves creating a server-side framework that supports TypeScript rendering and integrates it with Rust using Actix. The challenge is ensuring high performance and scalability for SSR.", "completion": "175 hours, Medium"}
{"prompt": "Migrate CI/CD pipelines from GitLab to GitHub Actions for a large-scale project. This involves converting existing workflows, setting up remote caching to speed up builds, and implementing matrix testing across multiple architectures to ensure robust cross-platform support.", "completion": "175 hours, Easy"}
{"prompt": "MetaCall Rust Loader Support project focuses on completing Rust language support in MetaCall by implementing Foreign Function Interface (FFI), introspection capabilities, and integration with the Rust compiler API to provide seamless interoperability with polyglot environments.", "completion": "350 hours, Hard"}
{"prompt": "Implement a WebAssembly solution to run MetaCall in the browser, which includes creating a minimal ISO image that can execute multiple programming languages. The challenge is ensuring interoperability across various languages within the browser environment using WebAssembly.", "completion": "350 hours, Hard"}
{"prompt": "Refactor an existing monolithic C application into a modular design, creating multiple independent components with clear APIs for better maintainability and scalability. The project requires careful planning of module boundaries and dependencies, along with detailed unit and integration testing for each component.", "completion": "500 hours, Hard"}
{"prompt": "Develop a Python-based microservice for processing large datasets. The service must be scalable, using asynchronous I/O to handle high concurrency, and integrate with external APIs to fetch data. Performance testing and optimization will be necessary to handle datasets in the range of several terabytes.", "completion": "300 hours, Hard"}
{"prompt": "Develop a real-time collaboration feature for an existing chat application. This includes implementing WebSockets for bi-directional communication, integrating user authentication and access control, and ensuring data consistency across all connected clients. This requires significant backend and frontend work.", "completion": "250 hours, Medium"}
{"prompt": "Implement a machine learning pipeline using TensorFlow. The task involves preprocessing raw data, designing and training a model for predictive analytics, and deploying the model into a production environment. Performance optimization and monitoring are critical components of the project.", "completion": "450 hours, Hard"}
{"prompt": "Reimplement the frontend for a legacy web application in React, ensuring full compatibility with existing REST APIs while refactoring the UI components for better maintainability. This involves designing a modern, user-friendly interface, optimizing for performance, and ensuring responsive design across all devices.", "completion": "300 hours, Medium"}
{"prompt": "Build an interactive dashboard in React for displaying real-time analytics data, utilizing WebSocket connections for live updates. The dashboard should support custom visualizations and allow users to filter and analyze data. The project also includes writing unit and integration tests for the components.", "completion": "250 hours, Medium"}
{"prompt": "Implement OAuth2 authentication for a RESTful API using a modern framework like Django or Flask. The task involves setting up OAuth2 server endpoints, securing API routes, and handling token-based authentication for both web and mobile clients. Additional work includes writing tests and documentation.", "completion": "150 hours, Medium"}
{"prompt": "MetaCall has multiple runtimes embedded in it, and one of its objectives is to be as cross-platform as possible. My plan is to improve the cross-platform support for the main supported platforms as follows:\n\nMacOS: I intend to implement the build script for MacOS from scratch with automated CI, similar to how the Windows distributable was created. I'll also add tests and enhance the install script for Linux by adding MacOS support.\nWindows: I'll work on improving the language support [1][2] for Windows, including adding respective tests and enhancing the install script.\nLinux: I will add support for new architectures in Linux with the necessary tests (potentially using Docker multi-architecture for these tests) and update the install script to support those architectures.\n", "completion": "175 hours,  Medium"}
{"prompt": "My plan for this project is to implement a CLI with a separated API that will enable the generation of compact Docker images with the MetaCall runtime. Since Docker doesn't allow selective merging of multiple layers into one with efficient caching, I plan to address this by templating the Dockerfile itself. However, I will use the Buildkit API to create a more robust solution, leveraging all its features, such as caching.I also recognize the importance of ensuring that this project runs in a rootless and daemonless manner within a Dockerized environment. I intend to make it executable inside Docker without special permissions or a Docker daemon, enabling it to run seamlessly in Kubernetes clusters. This will include support for pushing and pulling the resulting images from a private registry.\n\nMy approach will focus on making the project efficient and sandboxed, targeting FaaS development while producing compact images in terms of size and dependencies. This will help reduce bandwidth usage and minimize the attack surface.", "completion": "350 hours,  Medium"}
{"prompt": "I plan to work on implementing a CLI for deploying projects into MetaCall FaaS. My goal is to ensure that this Deploy CLI can be integrated seamlessly with the existing MetaCall CLI. The purpose of this project is to provide both an interactive and an automated method for deploying projects into MetaCall FaaS.  I will also focus on making the Deploy CLI fully integrable with the MetaCall CLI, creating a self-contained distributable with all the compiled code. This distributable should be launchable or invocable from an external CLI.\n", "completion": "175 hours,  Easy"}
{"prompt": "I intend to reimplement MetaCall FaaS with a simpler and less performant design. The goal of this reimplementation is to create a straightforward and portable FaaS that can be run from the CLI, enabling me to locally test functions and complete projects that can later be deployed into MetaCall FaaS. I plan to mimic the MetaCall FaaS REST API but without requiring authentication, and I will include only the essential features needed for development.\nTo improve deployment, I aim to make MetaCall FaaS integrable with MetaCall CLI, providing a self-contained distributable that includes all the compiled code. This distributable should be launchable or invokable from an external CLI via API.\n", "completion": "350 hours,  Medium"}
{"prompt": "I plan to leverage the recent support for the C language in MetaCall to simplify and enhance its design by reimplementing the CLI in C and potentially other languages. This approach will allow MetaCall to compile itself or provide core functionality via plugins. My goal is to simplify, abstract, and make the design more extensible across multiple languages. I will also focus on improving both the CLI and REPL interfaces. My aim is to provide a unified tool that can be easily extended with existing projects, such as the Polyglot REPL and the Deploy CLI.\n", "completion": "350 hours,  Medium"}
{"prompt": "I plan to build on MetaCall's recent support for inlining other languages into Rust through its macro system. This feature will enable me to integrate languages like Python or TypeScript into Rust seamlessly. My goal is to create a Proof of Concept for an Actix-based server that incorporates Server-Side Rendering (SSR) using TypeScript.\nThe concept involves developing a small framework that leverages MetaCall to allow writing endpoint handlers with embedded TypeScript in a straightforward manner.\nAs part of the project, I intend to include benchmarks to compare the solution to other SSR frameworks or establish a baseline for future optimizations in MetaCall's TypeScript support.", "completion": "175 hours,  Medium"}
{"prompt": "I intend to build upon MetaCall's recent support for Rust, which allows embedding Rust code into other languages like NodeJS and Python. Currently, the loader can compile and load Rust code, retrieving a list of functions and types. My objective is to implement FFI (Foreign Function Interface) calls to expand this functionality.\n\nAfter enabling FFI calls, I will implement additional features such as metacall_load_from_memory (essentially an eval) and metacall_load_from_package to support loading precompiled packages.", "completion": "350 hours,  Hard"}
{"prompt": "For this project, I intend to create a Proof of Concept to run MetaCall in the browser. My approach involves creating a very minimal ISO image capable of being virtualized inside a browser to execute MetaCall, or finding another way to execute MetaCall in the browser with a few languages to showcase interoperability. The goal is to establish a foundation for running polyglot applications seamlessly in the browser.", "completion": "350 hours,  Hard"}
{"prompt": "The objective of my addition to the project is to implement debugging support in MetaCall, primarily for the Visual Studio Code IDE, though it could also work with other IDEs that support debugging protocols from Node.js, Python, and similar languages. To achieve this, I may need to modify the MetaCall Core to enable debugging or develop a new project that integrates debugging capabilities into the MetaCall CLI or Core. This is a highly experimental effort at the time of writing, but some preliminary research has already been conducted.\n\nThe straightforward part of the implementation involves launching the runtime with the debugging protocol enabled-for instance, using a command like node --inspect script.js. However, the more challenging aspect will be attaching to running processes, as this requires addressing certain complexities within the MetaCall Core.\n\nThe ultimate goal of this addition is to enable debugging of polyglot applications, allowing developers to add breakpoints and transition between languages seamlessly within Visual Studio Code (or a similar IDE). Achieving this may require implementing a custom launch plugin to unify existing launcher plugins.", "completion": "350 hours,  Hard"}
{"prompt": "My objective is to migrate the CI/CD pipelines and deployments to GitHub Actions and GitHub Container Registry. This migration will involve writing GitHub Actions workflows to automate the process and ensure the project is built for every push and pull request event. I plan to implement remote caching for faster builds, set up a CI/CD matrix for testing across various architectures, and enhance the overall developer experience for contributors. ", "completion": "175 hours,  Easy"}
{"prompt": "I will make  the implementation and completion of CI/CD builds for Windows, Linux, and MacOS, enabling the distribution of cross-platform binaries for MetaCall.", "completion": "175 hours,  Medium"}
{"prompt": "I will make a command-line interface and library that can selectively compose Docker images and run them inside Docker/Kubernetes for MetaCall with efficient caching and a compact size.", "completion": "350 hours,  Medium"}
{"prompt": "I will add a command-line interface capable of deploying projects and managing deployments within MetaCall FaaS.\"", "completion": "175 hours,  Easy"}
{"prompt": "I will add an embeddable library that can be used for locally testing MetaCall projects as though they were hosted on the FaaS.", "completion": "350 hours,  Medium"}
{"prompt": "I will make a fully refactored MetaCall CLI with a bootstrappable design that includes all current functionality and improvements, implemented as modular CLI plugins.", "completion": "350 hours,  Medium"}
{"prompt": "I will make a lightweight framework built on Actix that enables inline server-side rendering with React (TypeScript)", "completion": "175 hours,  Medium"}
{"prompt": "I will make a comprehensive Rust language support for MetaCall, including FFI functionality and introspection capabilities using the Rust Compiler API.", "completion": "350 hours,  Hard"}
{"prompt": " I will make a functional version of MetaCall running in the browser (via WebAssembly), demonstrating interoperability between different languages.", "completion": "350 hours,  Hard"}
{"prompt": "I will make a fully functional Visual Studio Code extension capable of debugging polyglot applications using MetaCall.", "completion": "350 hours,  Hard"}
{"prompt": "I will make a standardized implementation of all MetaCall pipelines on platforms other than GitHub.", "completion": "175 hours,  Easy"}
{"prompt": "MetaCall has multiple runtimes embedded in it, and one of its objectives is to be as cross-platform as possible. Each runtime comes with its own dependencies, which sometimes result in a large and complex dependency tree that is difficult to manage. I understand that you are currently using Guix as the build system on Linux, and you've successfully compiled MetaCall to make it completely self-contained (in Linux for amd64 at the time of writing). This makes it possible to install MetaCall even on a BusyBox environment and have it function properly without any other system dependencies. I also see that the current implementation of the build system is divided into three repositories: Distributable Linux: https://github.com/metacall/distributable-linux\nDistributable Windows: https://github.com/metacall/distributable-windows\nDistributable MacOS: https://github.com/metacall/distributable-macos\nMy plan is to improve the cross-platform support for the main supported platforms as follows:\n\nMacOS: I intend to implement the build script for MacOS from scratch with automated CI, similar to how the Windows distributable was created. I'll also add tests and enhance the install script for Linux by adding MacOS support.\nWindows: I'll work on improving the language support [1][2] for Windows, including adding respective tests and enhancing the install script.\nLinux: I will add support for new architectures in Linux with the necessary tests (potentially using Docker multi-architecture for these tests) and update the install script to support those architectures.\nAdditionally, I'll create a README for this repository to document the three repositories and build systems, ensuring everything is clearly explained.\n", "completion": "175 hours,  Medium"}
{"prompt": "I see that MetaCall is currently offered as a Docker image on Docker Hub, including four tags (deps, dev, runtime, and cli) with only one architecture (amd64). At the moment, all languages are packaged into the image at once, resulting in a large image size, particularly in the dev tag. My plan for this project is to implement a CLI with a separated API that will enable the generation of compact Docker images with the MetaCall runtime. Since Docker doesn't allow selective merging of multiple layers into one with efficient caching, I plan to address this by templating the Dockerfile itself. However, I will use the Buildkit API to create a more robust solution, leveraging all its features, such as caching.I also recognize the importance of ensuring that this project runs in a rootless and daemonless manner within a Dockerized environment. I intend to make it executable inside Docker without special permissions or a Docker daemon, enabling it to run seamlessly in Kubernetes clusters. This will include support for pushing and pulling the resulting images from a private registry.\n\nMy approach will focus on making the project efficient and sandboxed, targeting FaaS development while producing compact images in terms of size and dependencies. This will help reduce bandwidth usage and minimize the attack surface.", "completion": "350 hours,  Medium"}
{"prompt": "I plan to work on implementing a CLI for deploying projects into MetaCall FaaS. My goal is to ensure that this Deploy CLI can be integrated seamlessly with the existing MetaCall CLI. The purpose of this project is to provide both an interactive and an automated method for deploying projects into MetaCall FaaS. I understand that some functionalities are already provided and that some tests have been implemented, but I intend to expand upon this work.\n\nI will ensure the CLI is thoroughly tested through automated testing, and I will complete all the requirements outlined in the TODO list. To enhance deployment capabilities, I will also focus on making the Deploy CLI fully integrable with the MetaCall CLI, creating a self-contained distributable with all the compiled code. This distributable should be launchable or invocable from an external CLI.\n", "completion": "175 hours,  Easy"}
{"prompt": "I intend to reimplement MetaCall FaaS with a simpler and less performant design. The goal of this reimplementation is to create a straightforward and portable FaaS that can be run from the CLI, enabling me to locally test functions and complete projects that can later be deployed into MetaCall FaaS. This aspect is crucial for supporting the developer workflow when building distributed polyglot applications.\nI plan to mimic the MetaCall FaaS REST API but without requiring authentication, and I will include only the essential features needed for development. I will also ensure this repository shares components with MetaCall FaaS through MetaCall Protocol, allowing code reuse between the repositories.\nTo improve deployment, I aim to make MetaCall FaaS integrable with MetaCall CLI, providing a self-contained distributable that includes all the compiled code. This distributable should be launchable or invokable from an external CLI via API.\n", "completion": "350 hours,  Medium"}
{"prompt": "I plan to leverage the recent support for the C language in MetaCall to simplify and enhance its design by reimplementing the CLI in C and potentially other languages. This approach will allow MetaCall to compile itself or provide core functionality via plugins. My goal is to simplify, abstract, and make the design more extensible across multiple languages.\nTo achieve this, I intend to separate the current commands (e.g., load, inspect, call) into individual single-function files, with each file mapped to a specific command. I will also focus on improving both the CLI and REPL interfaces.\nI will unify this interface into a pluggeable and standardized system. This will make it consistent and ready for future extensions, such as adding support for libseccmp capabilities through flags and implementing it as a plugin.\nThe REPL mode will also be extended. It will continue to support commands like loading files, calling functions, and inspecting loaded functions but will gain the ability to add extra commands or launch sub-REPLs or CLIs from separate repositories. My aim is to provide a unified tool that can be easily extended with existing projects, such as the Polyglot REPL and the Deploy CLI.\nFor CLI and REPL parsing, I intend to reimplement most of the functionality in a high-level language like Python (preferred for easier deployment in Guix) or Node.js. This will allow the CLI to be fully bootstrapped from scratch while keeping the design modular and efficient.\nTo start, I will evaluate the current CLI and REPL functionality, which can be downloaded from here. Before proceeding with the refactor, I will present a detailed design proposal for review and discussion with the staff.", "completion": "350 hours,  Medium"}
{"prompt": "I plan to build on MetaCall's recent support for inlining other languages into Rust through its macro system. This feature will enable me to integrate languages like Python or TypeScript into Rust seamlessly. My goal is to create a Proof of Concept for an Actix-based server that incorporates Server-Side Rendering (SSR) using TypeScript.\nThe concept involves developing a small framework that leverages MetaCall to allow writing endpoint handlers with embedded TypeScript in a straightforward manner. To achieve this, I will extend the Rust Port by adding the necessary functionality to support this use case.\nAs part of the project, I intend to include benchmarks to compare the solution to other SSR frameworks or establish a baseline for future optimizations in MetaCall's TypeScript support. Additionally, I will create documentation and examples to demonstrate the framework's functionality and ensure its reusability for other developers.", "completion": "175 hours,  Medium"}
{"prompt": "I intend to build upon MetaCall's recent support for Rust, which allows embedding Rust code into other languages like NodeJS and Python. Currently, the loader can compile and load Rust code, retrieving a list of functions and types. My objective is to implement FFI (Foreign Function Interface) calls to expand this functionality.\n\nI have reviewed some options for FFI, such as using the abi_stable crate, but its API is quite complex and has limitations, like lack of async support. To address this, I plan to explore alternatives, including using the Rust Compiler API to automatically generate stubs for functions on the fly. Since the same compiler version is used to build and call the code, making the ABI stable may not be necessary.\n\nAfter enabling FFI calls, I will implement additional features such as metacall_load_from_memory (essentially an eval) and metacall_load_from_package to support loading precompiled packages. I plan to utilize the rlib format, particularly the dylib variant, which is the dynamic library version of rlib and contains the required metadata for introspection in the .rustc section.", "completion": "350 hours,  Hard"}
{"prompt": "Nowadays, WebAssembly is gaining a lot of traction, enabling more functionality over time and supporting a wide variety of languages as a compilation target. One of the earliest attempts to virtualize Linux in the browser was JSLinux, developed by Fabrice Bellard. Initially implemented using asm.js and existing technologies before WebAssembly's standardization, JSLinux has been refactored over time. However, there are now more powerful and production-ready alternatives, such as CheerpX-a modern compiler forked from LLVM for compiling C/C++ to WebAssembly.\n\nFor this project, I intend to create a Proof of Concept to run MetaCall in the browser. While technologies like JSLinux or CheerpX might be considered, I am open to exploring alternatives without restrictions. My approach involves creating a very minimal ISO image capable of being virtualized inside a browser to execute MetaCall, or finding another way to execute MetaCall in the browser with a few languages to showcase interoperability. The goal is to establish a foundation for running polyglot applications seamlessly in the browser.", "completion": "350 hours,  Hard"}
{"prompt": "I intend to implement debugging support in MetaCall, primarily for the Visual Studio Code IDE, though it could also work with other IDEs that support debugging protocols from Node.js, Python, and similar languages. To achieve this, I may need to modify the MetaCall Core to enable debugging or develop a new project that integrates debugging capabilities into the MetaCall CLI or Core. ", "completion": "350 hours,  Hard"}
{"prompt": "Currently, the Continuous Integration and Continuous Deployment (CI/CD) pipelines are hosted on GitLab and use GitLab CI for automation. We manage our automated testing and deployment processes through specific scripts integrated with GitLab CI. My objective is to migrate these CI/CD pipelines and deployments to GitHub Actions and GitHub Container Registry. GitHub Actions is free for public projects and does not impose limits on CI/CD minutes per month, making it an effective platform for testing and deploying. Additionally, centralizing all Docker images within the GitHub organization using GitHub Container Registry will help avoid rate-limiting issues with Docker Hub.\n\nThis migration will involve writing GitHub Actions workflows to automate the process and ensure the project is built for every push and pull request event. I plan to implement remote caching for faster builds, set up a CI/CD matrix for testing across various architectures, and enhance the overall developer experience for contributors. Additionally, I aim to document the entire CI/CD strategy and workflow comprehensively so that the community can adopt it as a best practice.", "completion": "175 hours,  Easy"}
{"prompt": "MetaCall has multiple runtimes embedded in it, and one of its objectives is to be as cross-platform as possible. Each runtime comes with its own dependencies, which sometimes result in a large and complex dependency tree that is difficult to manage. I understand that you are currently using Guix as the build system on Linux, and you've successfully compiled MetaCall to make it completely self-contained (in Linux for amd64 at the time of writing). This makes it possible to install MetaCall even on a BusyBox environment and have it function properly without any other system dependencies. I also see that the current implementation of the build system is divided into three repositories: Distributable Linux: https://github.com/metacall/distributable-linux\nDistributable Windows: https://github.com/metacall/distributable-windows\nDistributable MacOS: https://github.com/metacall/distributable-macos\nMy plan is to improve the cross-platform support for the main supported platforms as follows:\n\nMacOS: I intend to implement the build script for MacOS from scratch with automated CI, similar to how the Windows distributable was created. I'll also add tests and enhance the install script for Linux by adding MacOS support.\nWindows: I'll work on improving the language support [1][2] for Windows, including adding respective tests and enhancing the install script.\nLinux: I will add support for new architectures in Linux with the necessary tests (potentially using Docker multi-architecture for these tests) and update the install script to support those architectures.\nAdditionally, I'll create a README for this repository to document the three repositories and build systems, ensuring everything is clearly explained.\n", "completion": "175 hours,  Medium"}
{"prompt": "I see that MetaCall is currently offered as a Docker image on Docker Hub, including four tags (deps, dev, runtime, and cli) with only one architecture (amd64). At the moment, all languages are packaged into the image at once, resulting in a large image size, particularly in the dev tag. My plan for this project is to implement a CLI with a separated API that will enable the generation of compact Docker images with the MetaCall runtime. Since Docker doesn't allow selective merging of multiple layers into one with efficient caching, I plan to address this by templating the Dockerfile itself. However, I will use the Buildkit API to create a more robust solution, leveraging all its features, such as caching.I also recognize the importance of ensuring that this project runs in a rootless and daemonless manner within a Dockerized environment. I intend to make it executable inside Docker without special permissions or a Docker daemon, enabling it to run seamlessly in Kubernetes clusters. This will include support for pushing and pulling the resulting images from a private registry.\n\nMy approach will focus on making the project efficient and sandboxed, targeting FaaS development while producing compact images in terms of size and dependencies. This will help reduce bandwidth usage and minimize the attack surface.", "completion": "350 hours,  Medium"}
{"prompt": "I plan to work on implementing a CLI for deploying projects into MetaCall FaaS. My goal is to ensure that this Deploy CLI can be integrated seamlessly with the existing MetaCall CLI. The purpose of this project is to provide both an interactive and an automated method for deploying projects into MetaCall FaaS. I understand that some functionalities are already provided and that some tests have been implemented, but I intend to expand upon this work.\n\nI will ensure the CLI is thoroughly tested through automated testing, and I will complete all the requirements outlined in the TODO list. To enhance deployment capabilities, I will also focus on making the Deploy CLI fully integrable with the MetaCall CLI, creating a self-contained distributable with all the compiled code. This distributable should be launchable or invocable from an external CLI.\n", "completion": "175 hours,  Easy"}
{"prompt": "I intend to reimplement MetaCall FaaS with a simpler and less performant design. The goal of this reimplementation is to create a straightforward and portable FaaS that can be run from the CLI, enabling me to locally test functions and complete projects that can later be deployed into MetaCall FaaS. This aspect is crucial for supporting the developer workflow when building distributed polyglot applications.\nI plan to mimic the MetaCall FaaS REST API but without requiring authentication, and I will include only the essential features needed for development. I will also ensure this repository shares components with MetaCall FaaS through MetaCall Protocol, allowing code reuse between the repositories.\nTo improve deployment, I aim to make MetaCall FaaS integrable with MetaCall CLI, providing a self-contained distributable that includes all the compiled code. This distributable should be launchable or invokable from an external CLI via API.\n", "completion": "350 hours,  Medium"}
{"prompt": "I plan to leverage the recent support for the C language in MetaCall to simplify and enhance its design by reimplementing the CLI in C and potentially other languages. This approach will allow MetaCall to compile itself or provide core functionality via plugins. My goal is to simplify, abstract, and make the design more extensible across multiple languages.\nTo achieve this, I intend to separate the current commands (e.g., load, inspect, call) into individual single-function files, with each file mapped to a specific command. I will also focus on improving both the CLI and REPL interfaces.\nI will unify this interface into a pluggeable and standardized system. This will make it consistent and ready for future extensions, such as adding support for libseccmp capabilities through flags and implementing it as a plugin.\nThe REPL mode will also be extended. It will continue to support commands like loading files, calling functions, and inspecting loaded functions but will gain the ability to add extra commands or launch sub-REPLs or CLIs from separate repositories. My aim is to provide a unified tool that can be easily extended with existing projects, such as the Polyglot REPL and the Deploy CLI.\nFor CLI and REPL parsing, I intend to reimplement most of the functionality in a high-level language like Python (preferred for easier deployment in Guix) or Node.js. This will allow the CLI to be fully bootstrapped from scratch while keeping the design modular and efficient.\nTo start, I will evaluate the current CLI and REPL functionality, which can be downloaded from here. Before proceeding with the refactor, I will present a detailed design proposal for review and discussion with the staff.", "completion": "350 hours,  Medium"}
{"prompt": "I plan to build on MetaCall's recent support for inlining other languages into Rust through its macro system. This feature will enable me to integrate languages like Python or TypeScript into Rust seamlessly. My goal is to create a Proof of Concept for an Actix-based server that incorporates Server-Side Rendering (SSR) using TypeScript.\nThe concept involves developing a small framework that leverages MetaCall to allow writing endpoint handlers with embedded TypeScript in a straightforward manner. To achieve this, I will extend the Rust Port by adding the necessary functionality to support this use case.\nAs part of the project, I intend to include benchmarks to compare the solution to other SSR frameworks or establish a baseline for future optimizations in MetaCall's TypeScript support. Additionally, I will create documentation and examples to demonstrate the framework's functionality and ensure its reusability for other developers.", "completion": "175 hours,  Medium"}
{"prompt": "I intend to build upon MetaCall's recent support for Rust, which allows embedding Rust code into other languages like NodeJS and Python. Currently, the loader can compile and load Rust code, retrieving a list of functions and types. My objective is to implement FFI (Foreign Function Interface) calls to expand this functionality.\n\nI have reviewed some options for FFI, such as using the abi_stable crate, but its API is quite complex and has limitations, like lack of async support. To address this, I plan to explore alternatives, including using the Rust Compiler API to automatically generate stubs for functions on the fly. Since the same compiler version is used to build and call the code, making the ABI stable may not be necessary.\n\nAfter enabling FFI calls, I will implement additional features such as metacall_load_from_memory (essentially an eval) and metacall_load_from_package to support loading precompiled packages. I plan to utilize the rlib format, particularly the dylib variant, which is the dynamic library version of rlib and contains the required metadata for introspection in the .rustc section.", "completion": "350 hours,  Hard"}
{"prompt": "Nowadays, WebAssembly is gaining a lot of traction, enabling more functionality over time and supporting a wide variety of languages as a compilation target. One of the earliest attempts to virtualize Linux in the browser was JSLinux, developed by Fabrice Bellard. Initially implemented using asm.js and existing technologies before WebAssembly's standardization, JSLinux has been refactored over time. However, there are now more powerful and production-ready alternatives, such as CheerpX-a modern compiler forked from LLVM for compiling C/C++ to WebAssembly.\n\nFor this project, I intend to create a Proof of Concept to run MetaCall in the browser. While technologies like JSLinux or CheerpX might be considered, I am open to exploring alternatives without restrictions. My approach involves creating a very minimal ISO image capable of being virtualized inside a browser to execute MetaCall, or finding another way to execute MetaCall in the browser with a few languages to showcase interoperability. The goal is to establish a foundation for running polyglot applications seamlessly in the browser.", "completion": "350 hours,  Hard"}
{"prompt": "I intend to implement debugging support in MetaCall, primarily for the Visual Studio Code IDE, though it could also work with other IDEs that support debugging protocols from Node.js, Python, and similar languages. To achieve this, I may need to modify the MetaCall Core to enable debugging or develop a new project that integrates debugging capabilities into the MetaCall CLI or Core. ", "completion": "350 hours,  Hard"}
{"prompt": "Currently, the Continuous Integration and Continuous Deployment (CI/CD) pipelines are hosted on GitLab and use GitLab CI for automation. We manage our automated testing and deployment processes through specific scripts integrated with GitLab CI. My objective is to migrate these CI/CD pipelines and deployments to GitHub Actions and GitHub Container Registry. GitHub Actions is free for public projects and does not impose limits on CI/CD minutes per month, making it an effective platform for testing and deploying. Additionally, centralizing all Docker images within the GitHub organization using GitHub Container Registry will help avoid rate-limiting issues with Docker Hub.\n\nThis migration will involve writing GitHub Actions workflows to automate the process and ensure the project is built for every push and pull request event. I plan to implement remote caching for faster builds, set up a CI/CD matrix for testing across various architectures, and enhance the overall developer experience for contributors. Additionally, I aim to document the entire CI/CD strategy and workflow comprehensively so that the community can adopt it as a best practice.", "completion": "175 hours,  Easy"}
{"prompt": "I intend to develop a functional AI chatbot designed to handle basic gprMax support queries effectively.", "completion": "350 hours, Medium"}
{"prompt": "I intend to make an initial working port of the FDTD solver engine for gprMax using Apple Metal.", "completion": "350 hours, Medium"}
{"prompt": "I intend to make comprehensive benchmarks and measurable improvements in the performance of the current CUDA and OpenCL-based solvers.", "completion": "175 hours, Medium"}
{"prompt": "I intend to make detailed benchmarks and tangible improvements to the performance of the current OpenMP-based solver on Apple silicon hardware.", "completion": "175 hours, Medium"}
{"prompt": "I intend to make comprehensive benchmarks and measurable performance improvements to the current CPU solver through optimized memory and cache access.", "completion": "350 hours, Medium"}
{"prompt": "I intend to make a basic working model and framework that demonstrates the de-coupling of model building and execution, improving overall performance.", "completion": "350 hours, Hard"}
{"prompt": "I intend to make a functional initial port of the FDTD solver engine for gprMax using HIP.", "completion": "350 hours, Medium"}
{"prompt": "I intend to develop an AI chatbot that can handle basic questions and inquiries about gprMax. My plan is to harvest question-and-answer data from the Google group to train an AI chatbot capable of providing automated responses to common support questions about gprMax.", "completion": "350 hours, Medium"}
{"prompt": "I intend to develop a port of the FDTD solver engine for gprMax using Apple Metal while leveraging the significant performance benefits of GPU parallelization. The project will involve porting existing code from the PyCUDA or PyOpenCL-based solvers currently in use to the Apple Metal framework.", "completion": "350 hours, Medium"}
{"prompt": "I intend to optimize the existing CUDA and OpenCL-based solvers to further enhance their performance. My goal is to further fine-tune and optimize these solvers, written using PyCUDA and PyOpenCL, to ensure even better performance as simulations grow larger and more complex.", "completion": "175 hours, Medium"}
{"prompt": "I intend to maximize the performance of gprMax on Apple silicon hardware. For CPU-based parallelization, the current implementation uses OpenMP, which has performed well on Intel-based CPUs with gcc (on Linux/macOS) and Microsoft Visual Studio compilers. My goal is to explore and implement optimizations specifically tailored for Apple silicon CPUs to enhance gprMax's performance.", "completion": "175 hours, Medium"}
{"prompt": "I intend to optimize the performance of the CPU-based solver in gprMax by investigating strategies for improving memory and cache access. The solver, based on the Finite-Difference Time-Domain (FDTD) method, is heavily constrained by memory bandwidth. My approach will explore techniques such as FDTD XPU technology to enhance memory and cache efficiency.", "completion": "350 hours, Medium"}
{"prompt": "I intend to investigate de-coupling the model building and execution phases in gprMax to address performance bottlenecks. My plan is to make the model building and execution phases more independent and implement a queuing system to resolve the performance issue caused because a model can not be built until the previous one has finished executing under the current framework.", "completion": "350 hours, Hard"}
{"prompt": "I intend to develop a port of the FDTD solver engine for gprMax using the HIP (Heterogeneous-compute Interface for Portability) API. Since the performance of the solver is critical as simulations grow larger and more complex, my goal is to leverage the benefits of GPU parallelization.", "completion": "350 hours, Medium"}
{"prompt": "I intend to develop an AI chatbot that can handle basic questions and inquiries about gprMax. Currently, the gprMax user community actively engages with the development team through the GitHub issue tracker and the Google group. My plan is to harvest question-and-answer data from the Google group to train an AI chatbot capable of providing automated responses to common support questions about gprMax.", "completion": "350 hours, Medium"}
{"prompt": "I intend to develop a port of the FDTD solver engine for gprMax using Apple Metal. Since the solver's performance is critical as simulations grow larger and more complex, I aim to leverage the significant performance benefits of GPU parallelization. The project will involve porting existing code from the PyCUDA or PyOpenCL-based solvers currently in use to the Apple Metal framework.", "completion": "350 hours, Medium"}
{"prompt": "I intend to optimize the existing CUDA and OpenCL-based solvers to further enhance their performance. The solver, which is based on the Finite-Difference Time-Domain (FDTD) method, already benefits significantly from GPU parallelization, achieving speed-ups of up to 30x with CUDA compared to OpenMP-parallelized CPU implementations. My goal is to further fine-tune and optimize these solvers, written using PyCUDA and PyOpenCL, to ensure even better performance as simulations grow larger and more complex.", "completion": "175 hours, Medium"}
{"prompt": "I intend to maximize the performance of gprMax on Apple silicon hardware. While gprMax is primarily written in Python, some performance-critical components are implemented in Cython, which must be built and compiled. For CPU-based parallelization, the current implementation uses OpenMP, which has performed well on Intel-based CPUs with gcc (on Linux/macOS) and Microsoft Visual Studio compilers. My goal is to explore and implement optimizations specifically tailored for Apple silicon CPUs to enhance gprMax's performance.", "completion": "175 hours, Medium"}
{"prompt": "I intend to optimize the performance of the CPU-based solver in gprMax by investigating strategies for improving memory and cache access. While gprMax is predominantly written in Python, the performance-critical components are implemented in Cython and require building and compilation. The solver, based on the Finite-Difference Time-Domain (FDTD) method, is heavily constrained by memory bandwidth. My approach will explore techniques such as FDTD XPU technology to enhance memory and cache efficiency.", "completion": "350 hours, Medium"}
{"prompt": "I intend to investigate de-coupling the model building and execution phases in gprMax to address performance bottlenecks. Currently, the model building phase, which is mostly serial, runs on the CPU. After the model is built, it can be executed using either the CPU-based (OpenMP) or GPU-based (CUDA) solver. However, the next model cannot begin building until the previous one has finished executing, which can cause delays. My plan is to make the model building and execution phases more independent and implement a queuing system to resolve this performance issue", "completion": "350 hours, Hard"}
{"prompt": "I intend to develop a port of the FDTD solver engine for gprMax using the HIP (Heterogeneous-compute Interface for Portability) API. Since the performance of the solver is critical as simulations grow larger and more complex, my goal is to leverage the benefits of GPU parallelization. This project will involve porting the existing code from the PyCUDA-based solver to HIP. I plan to use automated translation tools, such as HIPIFY, to assist in the porting process.", "completion": "350 hours, Medium"}
{"prompt": "I intend to develop an AI chatbot that can handle basic questions and inquiries about gprMax. Currently, the gprMax user community actively engages with the development team through the GitHub issue tracker and the Google group. My plan is to harvest question-and-answer data from the Google group to train an AI chatbot capable of providing automated responses to common support questions about gprMax.\n\nExpected outcomes: A functional AI chatbot designed to handle basic gprMax support queries effectively.", "completion": "350 hours, Medium"}
{"prompt": "I intend to develop a port of the FDTD solver engine for gprMax using Apple Metal. Since the solver's performance is critical as simulations grow larger and more complex, I aim to leverage the significant performance benefits of GPU parallelization. The project will involve porting existing code from the PyCUDA or PyOpenCL-based solvers currently in use to the Apple Metal framework.\n\nExpected outcomes: An initial working port of the FDTD solver engine for gprMax using Apple Metal.", "completion": "350 hours, Medium"}
{"prompt": "I intend to optimize the existing CUDA and OpenCL-based solvers to further enhance their performance. The solver, which is based on the Finite-Difference Time-Domain (FDTD) method, already benefits significantly from GPU parallelization, achieving speed-ups of up to 30x with CUDA compared to OpenMP-parallelized CPU implementations. My goal is to further fine-tune and optimize these solvers, written using PyCUDA and PyOpenCL, to ensure even better performance as simulations grow larger and more complex.\n\nExpected outcomes: Comprehensive benchmarks and measurable improvements in the performance of the current CUDA and OpenCL-based solvers.", "completion": "175 hours, Medium"}
{"prompt": "I intend to maximize the performance of gprMax on Apple silicon hardware. While gprMax is primarily written in Python, some performance-critical components are implemented in Cython, which must be built and compiled. For CPU-based parallelization, the current implementation uses OpenMP, which has performed well on Intel-based CPUs with gcc (on Linux/macOS) and Microsoft Visual Studio compilers. My goal is to explore and implement optimizations specifically tailored for Apple silicon CPUs to enhance gprMax's performance.\n\nExpected outcomes: Detailed benchmarks and tangible improvements to the performance of the current OpenMP-based solver on Apple silicon hardware.", "completion": "175 hours, Medium"}
{"prompt": "I intend to optimize the performance of the CPU-based solver in gprMax by investigating strategies for improving memory and cache access. While gprMax is predominantly written in Python, the performance-critical components are implemented in Cython and require building and compilation. The solver, based on the Finite-Difference Time-Domain (FDTD) method, is heavily constrained by memory bandwidth. My approach will explore techniques such as FDTD XPU technology to enhance memory and cache efficiency.\n\nExpected outcomes: Comprehensive benchmarks and measurable performance improvements to the current CPU solver through optimized memory and cache access.", "completion": "350 hours, Medium"}
{"prompt": "I intend to investigate de-coupling the model building and execution phases in gprMax to address performance bottlenecks. Currently, the model building phase, which is mostly serial, runs on the CPU. After the model is built, it can be executed using either the CPU-based (OpenMP) or GPU-based (CUDA) solver. However, the next model cannot begin building until the previous one has finished executing, which can cause delays. My plan is to make the model building and execution phases more independent and implement a queuing system to resolve this performance issue.\n\nExpected outcomes: A basic working model and framework that demonstrates the de-coupling of model building and execution, improving overall performance.", "completion": "350 hours, Hard"}
{"prompt": "I intend to develop a port of the FDTD solver engine for gprMax using the HIP (Heterogeneous-compute Interface for Portability) API. Since the performance of the solver is critical as simulations grow larger and more complex, my goal is to leverage the benefits of GPU parallelization. This project will involve porting the existing code from the PyCUDA-based solver to HIP. I plan to use automated translation tools, such as HIPIFY, to assist in the porting process.\n\nExpected outcomes: A functional initial port of the FDTD solver engine for gprMax using HIP.", "completion": "350 hours, Medium"}
